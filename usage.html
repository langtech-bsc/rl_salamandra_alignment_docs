

<!DOCTYPE html>
<html class="writer-html5" lang="es" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Usage &mdash; documentación de RL - Salamandra Alignment - 0.1.0</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=ba61de6b"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/translations.js?v=f85f4cfb"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Índice" href="genindex.html" />
    <link rel="search" title="Búsqueda" href="search.html" />
    <link rel="next" title="RL - Salamandra Alignment" href="readme.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            RL - Salamandra Alignment
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" aria-label="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#experiment">Experiment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configuration-file-for-an-experiment">Configuration file for an Experiment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-an-experiment">Running an experiment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#debugging">Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#skipping-evaluation">Skipping evaluation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#subexperiments">Subexperiments</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="readme.html">RL - Salamandra Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">rl_salamandra_alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="history.html">History</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">RL - Salamandra Alignment</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Usage</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/usage.rst.txt" rel="nofollow"> Ver código fuente de la página</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h1>
<p>After <a class="reference internal" href="installation.html"><span class="doc">installing</span></a>, you will be able to run Reinforcement Learning experiments using the package.</p>
<section id="experiment">
<h2>Experiment<a class="headerlink" href="#experiment" title="Link to this heading"></a></h2>
<p>An experiment consists of two parts:</p>
<blockquote>
<div><ul class="simple">
<li><p>Training your model using a Reinforcement Learning algorithm</p></li>
<li><dl class="simple">
<dt>(Optional) Evaluating the resulting model</dt><dd><ul>
<li><p>Harness Evaluation</p></li>
<li><p>Local Evaluation</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>All the configurations and hyperparameters for an experiment must be specified in a <strong>configuration file</strong> in YAML.</p>
</div>
<p>When you run an experiment, training jobs and evaluation jobs are created and submitted to MareNostrum5 using SLURM.</p>
<p>For evaluation, some tasks are implemented in the Evaluation Harness. For those which are not, we use custom scripts (This is what we call «Local Evaluation»).</p>
<p>All evaluation jobs are submited to MareNostrum5 with dependencies to their respective training jobs.</p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Note that evaluation is optional: if you do not specify an <code class="docutils literal notranslate"><span class="pre">&quot;evaluation&quot;</span></code> field in your <cite>config.yaml</cite> file, then only training will happen.</p>
</div>
</section>
<section id="configuration-file-for-an-experiment">
<h2>Configuration file for an Experiment<a class="headerlink" href="#configuration-file-for-an-experiment" title="Link to this heading"></a></h2>
<p>First, you will need a configuration file in YAML for your experiment (The values marked with <code class="docutils literal notranslate"><span class="pre">None</span></code> are computed internally by the package):</p>
<div class="literal-block-wrapper docutils container" id="example-yaml-config">
<div class="code-block-caption"><span class="caption-text">Example YAML configuration file</span><a class="headerlink" href="#example-yaml-config" title="Link to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">execution</span><span class="p">:</span>
<span class="w">    </span><span class="nt">algorithm</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;dpo&quot;</span><span class="w"> </span><span class="c1"># Reinforcement Learning Algorithm</span>
<span class="w">    </span><span class="nt">venv</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;path_to_your_venv&gt;&quot;</span>
<span class="w">    </span><span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;path_to_your_output_dir&gt;&quot;</span>
<span class="w">    </span><span class="nt">distributed_config</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;DSZero3Offload&quot;</span><span class="w"> </span><span class="c1"># For distributed training in MN5</span>

<span class="nt">slurm</span><span class="p">:</span>
<span class="w">    </span><span class="nt">job-name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;your_slurm_job_name&gt;&quot;</span>
<span class="w">    </span><span class="c1"># output: None</span>
<span class="w">    </span><span class="c1"># error: None</span>
<span class="w">    </span><span class="nt">nodes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">cpus-per-task</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">80</span>
<span class="w">    </span><span class="nt">gres</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;gpu:4&quot;</span>
<span class="w">    </span><span class="nt">time</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;2:00:00&quot;</span>
<span class="w">    </span><span class="nt">account</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;bsc88&quot;</span>
<span class="w">    </span><span class="nt">qos</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;acc_debug&quot;</span>

<span class="nt">rl_script_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">dataset_name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;path_to_rl_dataset&gt;&quot;</span>

<span class="nt">model_config_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">model_name_or_path</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;path_to_model&gt;&quot;</span>
<span class="w">    </span><span class="c1"># output_dir: None</span>
<span class="w">    </span><span class="nt">attn_implementation</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;flash_attention_2&quot;</span>
<span class="w">    </span><span class="nt">torch_dtype</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;bfloat16&quot;</span>

<span class="nt">rl_config_args</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># RL configs are subclasses of transformers.TrainingArguments</span>

<span class="w">    </span><span class="c1"># Different RL algorithms have different uses of beta.</span>
<span class="w">    </span><span class="c1"># However, in most of them, it is the weight of the KL-divergence (Loss=reward+Beta*KL)</span>
<span class="w">    </span><span class="nt">beta</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="w">    </span><span class="nt">max_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8192</span>
<span class="w">    </span><span class="nt">max_prompt_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span><span class="w"> </span><span class="c1"># Default. When specified, you use the default data collator</span>
<span class="w">    </span><span class="nt">remove_unused_columns</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">dataset_num_proc</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="c1"># ====</span>
<span class="w">    </span><span class="c1"># From `TrainingArguments`:</span>
<span class="w">    </span><span class="c1"># ===</span>
<span class="w">    </span><span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5.0e-6</span>
<span class="w">    </span><span class="nt">num_train_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">bf16</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">eval_strategy</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;steps&quot;</span>
<span class="w">    </span><span class="nt">eval_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>

<span class="w">    </span><span class="c1"># logging_dir: None</span>
<span class="w">    </span><span class="c1"># local_rank: None</span>
<span class="w">    </span><span class="nt">report_to</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;wandb&quot;</span>
<span class="w">    </span><span class="c1"># These arguments help to manage GPU memory</span>
<span class="w">    </span><span class="nt">per_device_train_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">per_device_eval_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">gradient_accumulation_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">gradient_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="nt">environment</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Bash environment variables</span>
<span class="w">    </span><span class="nt">WANDB_PROJECT</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;salamandra_alignment&quot;</span>
<span class="w">    </span><span class="nt">WANDB_NAME</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;test_alignment&quot;</span>
<span class="w">    </span><span class="c1"># WANDB_DIR: None</span>

<span class="c1"># Evaluation is optional</span>
<span class="nt">evaluation</span><span class="p">:</span>
<span class="s">&quot;harness_tasks&quot;</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;flores_en-es&quot;</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;flores_es-ca&quot;</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;wnli_es&quot;</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;xlsum_es&quot;</span>
<span class="s">&quot;harness_slurm&quot;</span><span class="p p-Indicator">:</span>
<span class="c1"># job name, logs, and gpus are automatically computed</span>
<span class="w">    </span><span class="nt">qos</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;acc_bscls&quot;</span>
<span class="w">    </span><span class="nt">account</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;bsc88&quot;</span>
<span class="w">    </span><span class="nt">nodes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">time</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;12:00:00&quot;</span>
<span class="w">    </span><span class="c1"># job-name: None</span>
<span class="w">    </span><span class="c1"># output: None</span>
<span class="w">    </span><span class="c1"># error: None</span>
<span class="w">    </span><span class="c1"># cpus-per-task: None #</span>
<span class="w">    </span><span class="c1"># gres : None  # &quot;gpu:4&quot;</span>
</pre></div>
</div>
</div>
</section>
<section id="running-an-experiment">
<h2>Running an experiment<a class="headerlink" href="#running-an-experiment" title="Link to this heading"></a></h2>
<p>You can use your <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file to run an experiment, using the <span class="xref std std-ref">CLI</span>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>rl_salamandra_mn5<span class="w"> </span>config.yaml
</pre></div>
</div>
<p>This will generate <strong>and</strong> submit SLURM jobs to MareNostrum 5, you can find them in your <code class="docutils literal notranslate"><span class="pre">output_dir</span></code>.</p>
<section id="debugging">
<h3>Debugging<a class="headerlink" href="#debugging" title="Link to this heading"></a></h3>
<p>For debugging, use the <code class="docutils literal notranslate"><span class="pre">--debug</span></code> flag:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>rl_salamandra_mn5<span class="w"> </span>config.yaml<span class="w"> </span>--debug
</pre></div>
</div>
<p>In debugging mode, SLURM scripts will be generated but not submitted.</p>
</section>
<section id="skipping-evaluation">
<h3>Skipping evaluation<a class="headerlink" href="#skipping-evaluation" title="Link to this heading"></a></h3>
<p>If you only want to train but not evaluate nmodels, you can use the <code class="docutils literal notranslate"><span class="pre">--no_evaluation</span></code> flag</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>rl_salamandra_mn5<span class="w"> </span>config.yaml<span class="w"> </span>--no_evaluation
</pre></div>
</div>
<p>This will create the training and evaluation jobs for SLURM, but it will <strong>only</strong> submit the training jobs. This may be useful when the evaluation queue is long, or when you want to make a quick experiment.</p>
</section>
</section>
<section id="subexperiments">
<h2>Subexperiments<a class="headerlink" href="#subexperiments" title="Link to this heading"></a></h2>
<p>To experiment with different configurations of values, you can use <strong>lists</strong> in your <cite>config.yaml</cite> file.</p>
<p>For example, the following <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> for one experiment executes 12 subexperiments:</p>
<ul class="simple">
<li><p>6 runs of DPO: on 2 models with 3 learning rates, and</p></li>
<li><p>6 runs of KTO: on the same 2 models with the same 3 learning rates</p></li>
</ul>
<p>Note that both hyphens (<code class="docutils literal notranslate"><span class="pre">-</span></code>) and square brackes (<code class="docutils literal notranslate"><span class="pre">[]</span></code>) work for writing lists in YAML.</p>
<div class="literal-block-wrapper docutils container" id="example-subexperiments-config">
<div class="code-block-caption"><span class="caption-text">Setting up subexperiments</span><a class="headerlink" href="#example-subexperiments-config" title="Link to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">...</span>
<span class="nt">execution</span><span class="p">:</span>
<span class="w">    </span><span class="nt">algorithm</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;dpo&quot;</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;kto&quot;</span>
<span class="nn">...</span>
<span class="nt">model_config_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">model_name_or_path</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;model_1&quot;</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;model_2&quot;</span>
<span class="nn">...</span>
<span class="nt">rl_config_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">5.0e-6</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1.0e-5</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1.0e-6</span><span class="p p-Indicator">]</span>
<span class="nn">...</span>
</pre></div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>Note that any of the values in the configuration can be a list, <strong>except</strong> <code class="docutils literal notranslate"><span class="pre">output_dir</span></code> under <code class="docutils literal notranslate"><span class="pre">execution</span></code>. The <code class="docutils literal notranslate"><span class="pre">output_dir</span></code> must always be an absolute path.</p>
</div>
<p>Furthermore, for a given configuration file, all subexperiments generated from it share the same <code class="docutils literal notranslate"><span class="pre">evaluation</span></code> field, which will <strong>not</strong> be unfolded. This means that you can specify lists inside the <code class="docutils literal notranslate"><span class="pre">evaluation</span></code> field (for example, lists of evaluation tasks), and doing so will not create more subexperiments.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Pie de página">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Anterior</a>
        <a href="readme.html" class="btn btn-neutral float-right" title="RL - Salamandra Alignment" accesskey="n" rel="next">Siguiente <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Derechos de autor 2025, LangTech BSC.</p>
  </div>

  Compilado con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>